{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import sys\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.001\n",
    "HIDDEN_SIZE = 40\n",
    "PIXELS_PER_IMAGE = INPUT_SIZE = 28*28\n",
    "OUTPUT_SIZE = 10\n",
    "TRAIN_DATA_SIZE = 1000\n",
    "LAYERS_TOTAL = 3\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images, labels = x_train[0:TRAIN_DATA_SIZE] / 255, y_train[0:TRAIN_DATA_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_learn = images.reshape(TRAIN_DATA_SIZE, PIXELS_PER_IMAGE)\n",
    "outputs_to_learn = np.zeros((TRAIN_DATA_SIZE, OUTPUT_SIZE), dtype=np.float32)\n",
    "\n",
    "for ind, label in enumerate(labels):\n",
    "    outputs_to_learn[ind][label] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = x_test.reshape(len(x_test), PIXELS_PER_IMAGE) / 255\n",
    "test_outputs = np.zeros((len(y_test), OUTPUT_SIZE))\n",
    "\n",
    "for ind, label in enumerate(y_test):\n",
    "    test_outputs[ind][label] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def relu(x): return (x > 0) * x\n",
    "def relu_deriv(x): return x > 0\n",
    "\n",
    "weights = [\n",
    "    0.2 * np.random.rand(INPUT_SIZE, HIDDEN_SIZE) - 0.1,\n",
    "    0.2 * np.random.rand(HIDDEN_SIZE, OUTPUT_SIZE) - 0.1,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(data, weights, dropout=False):\n",
    "    layers = [None] * LAYERS_TOTAL\n",
    "\n",
    "    layers[0] = data\n",
    "    layers[1] = relu(np.dot(layers[0], weights[0]))\n",
    "\n",
    "    if(dropout):\n",
    "        dropout_mask = np.random.randint(2, size=layers[1].shape)\n",
    "        layers[1] *= dropout_mask * 2\n",
    "        layers[2] = np.dot(layers[1], weights[1])\n",
    "        return layers, dropout_mask\n",
    "        \n",
    "    layers[2] = np.dot(layers[1], weights[1])\n",
    "    return layers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 Error: 0.3366291726804473 Correct: 0.842\n",
      "\tTest-Error: 0.3235399234923692 \tTest-Acc: 0.8566\n",
      "Iteration: 20 Error: 0.3471193025846126 Correct: 0.836\n",
      "\tTest-Error: 0.32364472486345913 \tTest-Acc: 0.8565\n",
      "Iteration: 30 Error: 0.34830378243421456 Correct: 0.828\n",
      "\tTest-Error: 0.324124669239041 \tTest-Acc: 0.8566\n",
      "Iteration: 40 Error: 0.34822065104032435 Correct: 0.845\n",
      "\tTest-Error: 0.32448059110265015 \tTest-Acc: 0.8567\n",
      "Iteration: 50 Error: 0.3311886159250758 Correct: 0.844\n",
      "\tTest-Error: 0.32455538273650497 \tTest-Acc: 0.8571\n",
      "Iteration: 60 Error: 0.3497377531713737 Correct: 0.826\n",
      "\tTest-Error: 0.3244993357128973 \tTest-Acc: 0.8571\n",
      "Iteration: 70 Error: 0.35446405316542556 Correct: 0.826\n",
      "\tTest-Error: 0.32433549850353 \tTest-Acc: 0.8569\n",
      "Iteration: 80 Error: 0.3441347974294454 Correct: 0.836\n",
      "\tTest-Error: 0.32421454621763274 \tTest-Acc: 0.8572\n",
      "Iteration: 90 Error: 0.33698100868360453 Correct: 0.845\n",
      "\tTest-Error: 0.32423972577692806 \tTest-Acc: 0.857\n",
      "Iteration: 100 Error: 0.35241587199805463 Correct: 0.835\n",
      "\tTest-Error: 0.3243486420230946 \tTest-Acc: 0.8565\n",
      "Iteration: 110 Error: 0.3436574910484293 Correct: 0.84\n",
      "\tTest-Error: 0.3244043057995208 \tTest-Acc: 0.8566\n",
      "Iteration: 120 Error: 0.3412577076987085 Correct: 0.834\n",
      "\tTest-Error: 0.3243855047033099 \tTest-Acc: 0.8559\n",
      "Iteration: 130 Error: 0.34361206098741154 Correct: 0.834\n",
      "\tTest-Error: 0.32443940479625044 \tTest-Acc: 0.8561\n",
      "Iteration: 140 Error: 0.34114415739413567 Correct: 0.837\n",
      "\tTest-Error: 0.32454183919808316 \tTest-Acc: 0.8564\n",
      "Iteration: 150 Error: 0.3283948791952259 Correct: 0.852\n",
      "\tTest-Error: 0.3245096485767063 \tTest-Acc: 0.8563\n",
      "Iteration: 160 Error: 0.33081473817940765 Correct: 0.837\n",
      "\tTest-Error: 0.32444227160180583 \tTest-Acc: 0.8571\n",
      "Iteration: 170 Error: 0.3520878381500822 Correct: 0.833\n",
      "\tTest-Error: 0.3243667273623178 \tTest-Acc: 0.8571\n",
      "Iteration: 180 Error: 0.3311706097795893 Correct: 0.849\n",
      "\tTest-Error: 0.32416556407586034 \tTest-Acc: 0.8572\n",
      "Iteration: 190 Error: 0.3429298870564303 Correct: 0.834\n",
      "\tTest-Error: 0.32419850069855033 \tTest-Acc: 0.8571\n",
      "Iteration: 200 Error: 0.3391508459090332 Correct: 0.84\n",
      "\tTest-Error: 0.3243113669993958 \tTest-Acc: 0.8576\n",
      "Iteration: 210 Error: 0.3287176174367233 Correct: 0.834\n",
      "\tTest-Error: 0.3241951085775935 \tTest-Acc: 0.8576\n",
      "Iteration: 220 Error: 0.32996001247255335 Correct: 0.85\n",
      "\tTest-Error: 0.3244303176845875 \tTest-Acc: 0.8573\n",
      "Iteration: 230 Error: 0.3378670157155856 Correct: 0.839\n",
      "\tTest-Error: 0.3244665160185488 \tTest-Acc: 0.8575\n",
      "Iteration: 240 Error: 0.34108663905142583 Correct: 0.84\n",
      "\tTest-Error: 0.3244336718997943 \tTest-Acc: 0.8577\n",
      "Iteration: 250 Error: 0.33915788086111026 Correct: 0.84\n",
      "\tTest-Error: 0.3244243832565772 \tTest-Acc: 0.8573\n",
      "Iteration: 260 Error: 0.3446096888894394 Correct: 0.842\n",
      "\tTest-Error: 0.32449300790513586 \tTest-Acc: 0.8575\n",
      "Iteration: 270 Error: 0.34282720352255747 Correct: 0.835\n",
      "\tTest-Error: 0.32450644116841165 \tTest-Acc: 0.857\n",
      "Iteration: 280 Error: 0.33189241303287964 Correct: 0.85\n",
      "\tTest-Error: 0.3242092867738044 \tTest-Acc: 0.8575\n",
      "Iteration: 290 Error: 0.34087904412741954 Correct: 0.843\n",
      "\tTest-Error: 0.3242959072048082 \tTest-Acc: 0.8576\n",
      "Iteration: 300 Error: 0.35227342528342 Correct: 0.826\n",
      "\tTest-Error: 0.32443896688002194 \tTest-Acc: 0.8573\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 301):\n",
    "    error = 0.0\n",
    "    correct_counter = 0\n",
    "\n",
    "    for j in range(TRAIN_DATA_SIZE // BATCH_SIZE):\n",
    "        batch_start, batch_end = j * BATCH_SIZE, (j + 1) * BATCH_SIZE\n",
    "        \n",
    "        # Output\n",
    "        data = data_to_learn[batch_start:batch_end]#.reshape(BATCH_SIZE, 1, INPUT_SIZE)\n",
    "        layers, dropout_mask = nn(data=data, weights=weights, dropout=True)\n",
    "        \n",
    "        # Learning\n",
    "        layer_deltas = [None] * LAYERS_TOTAL\n",
    "        expected_output = outputs_to_learn[batch_start:batch_end]#.reshape(BATCH_SIZE, 1, OUTPUT_SIZE)\n",
    "        \n",
    "        error += np.sum((expected_output - layers[2]) ** 2)\n",
    "\n",
    "        for k in range(BATCH_SIZE):\n",
    "            correct_counter += np.argmax(expected_output[k]) == np.argmax(layers[2][k])\n",
    "\n",
    "        layer_deltas[2] = (expected_output - layers[2]) / BATCH_SIZE\n",
    "        layer_deltas[1] = np.dot(layer_deltas[2], weights[1].T) * relu_deriv(layers[1])\n",
    "        layer_deltas[1] *= dropout_mask\n",
    "\n",
    "        weights[1] += np.dot(layers[1].T, layer_deltas[2]) * ALPHA\n",
    "        weights[0] += np.dot(layers[0].T, layer_deltas[1]) * ALPHA\n",
    "    \n",
    "\n",
    "    if(i % 10 == 0):\n",
    "        print(\n",
    "            f\"Iteration: {i}\",\n",
    "            f\"Error: {error / TRAIN_DATA_SIZE}\",\n",
    "            f\"Correct: {correct_counter / TRAIN_DATA_SIZE}\"\n",
    "        )\n",
    "\n",
    "        error = 0\n",
    "        correct_counter = 0\n",
    "\n",
    "        for j in range(len(test_data)):\n",
    "            data = test_data[j].reshape(1, INPUT_SIZE)\n",
    "            layers = nn(data=data, weights=weights)\n",
    "\n",
    "            expected_output = test_outputs[j].reshape(1, OUTPUT_SIZE)\n",
    "\n",
    "            error += np.sum((expected_output - layers[2]) ** 2)\n",
    "            correct_counter += int(np.argmax(expected_output) == np.argmax(layers[2]))\n",
    "\n",
    "        print(\n",
    "            f\"\\tTest-Error: {error / len(test_data)}\",\n",
    "            f\"\\tTest-Acc: {correct_counter / len(test_data)}\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b243be397b004ca232554ba897cb822c69cb18e8d26499f4a19cd8366c84d8c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
